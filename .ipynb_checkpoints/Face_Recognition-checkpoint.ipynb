{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import VideoStream\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "import shutil\n",
    "import face_recognition\n",
    "import pickle\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding new face in face recognition dataset through live stream from webcam\n",
    "def add_face_data_from_video():\n",
    "\n",
    "    # load OpenCV's Haar cascade for face detection from disk\n",
    "    # haarcascade designed by OpenCV to detect the frontal face\n",
    "    cascade = 'haarcascades/haarcascade_frontalface_default.xml'\n",
    "\n",
    "    # Loading the Cascade classifier\n",
    "    detector = cv2.CascadeClassifier(cascade)\n",
    "    \n",
    "    while True:\n",
    "        name = input(\"Enter name of person: \")\n",
    "        new_folder = 'face_recognition_dataset/' + name\n",
    "        try:\n",
    "            os.makedirs(new_folder)\n",
    "            break\n",
    "        except OSError as e:\n",
    "            print('Folder Already exists')\n",
    "            action = input('To delete existing folder press d, else any other key to change name of entered folder: ')\n",
    "            if action=='d':\n",
    "                # os.rmdir: removes an empty directory\n",
    "                # shutil.emtree: removes a directory and all its contents\n",
    "                shutil.rmtree(new_folder)\n",
    "                os.makedirs(new_folder)\n",
    "                break\n",
    "\n",
    "    output = new_folder\n",
    "    print(\"To successfully encode the face please make atleast 10-15 clicks\")\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "\n",
    "    # Starting the video stream\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    total = 0\n",
    "    \n",
    "    # loop over the frames from the video stream\n",
    "    while True:\n",
    "        frame = cap.read()\n",
    "        orig = frame.copy()\n",
    "        \n",
    "        # resizing with keeping the aspect ratio same\n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        \n",
    "        # Detect faces in the grayscale frame:\n",
    "        # scaleFactor: Parameter specifying how much the image size is\n",
    "        # reduced at each image scale.\n",
    "        # minNeighbors: Parameter specifying how many neighbors each\n",
    "        # candidate rectangle should have to retain it.\n",
    "        # minSize: Minimum possible object size. Objects smaller than\n",
    "        # that are ignored.\n",
    "        rects = detector.detectMultiScale(\n",
    "            cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), scaleFactor=1.1, \n",
    "            minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        # loop over the face detections and draw them on the frame\n",
    "        for (x, y, w, h) in rects:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # show the output frame\n",
    "        \n",
    "        frame_msg = \"Press K to click, q to quit\"\n",
    "        cv2.imshow(frame_msg, frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `k` key was pressed, write the *original* frame to disk\n",
    "        # so we can later process it and use it for face recognition\n",
    "        if key == ord(\"k\"):\n",
    "            total += 1\n",
    "            p = os.path.sep.join([output, \"{}.png\".format(\n",
    "                str(total).zfill(5))])\n",
    "            cv2.imwrite(p, orig)\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        elif key == ord(\"q\"):\n",
    "            break    \n",
    "\n",
    "    # print the total faces saved and do a bit of cleanup\n",
    "    print(\"[INFO] {} face images stored in {}\".format(total, new_folder))\n",
    "    print(\"[INFO] cleaning up...\")\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_face_data_from_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adding new face in face recognition dataset through images\n",
    "def add_face_data_from_images():\n",
    "    \n",
    "    # haarcascade designed by OpenCV to detect the frontal face\n",
    "    cascade = 'haarcascades/haarcascade_frontalface_default.xml'\n",
    "\n",
    "    # Loading the Cascade classifier\n",
    "    detector = cv2.CascadeClassifier(cascade)\n",
    "    \n",
    "    imagePaths = []\n",
    "    while len(imagePaths)==0:\n",
    "        name = input('Enter name of folder in face_recognition_folder contaning images of person with that folder: ')\n",
    "        dir_path = 'face_recognition_dataset/' + name\n",
    "        imagePaths = list(paths.list_images(dir_path))\n",
    "        if len(imagePaths)==0:\n",
    "            print('Directory not found or directory is empty')\n",
    "    images = []\n",
    "    labels = []\n",
    "    for imagePath in imagePaths:\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = imutils.resize(image, width = 400)\n",
    "        # update the data and labels lists, respectively\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        os.remove(imagePath)\n",
    "    output = dir_path\n",
    "    \n",
    "    print(\"To effectively encode face please have atleast 10-15 pics\")\n",
    "    total = 0\n",
    "    for frame in images:\n",
    "        l = -1\n",
    "        while True:\n",
    "            cv2.imshow('Press s to select image, enter to rotate',frame)\n",
    "            l = cv2.waitKey(0) & 0xFF\n",
    "            if l==ord('s'):\n",
    "                break\n",
    "            else:\n",
    "                frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        if l:\n",
    "            cv2.destroyAllWindows()\n",
    "            orig = frame.copy()\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            # detect faces in the grayscale frame\n",
    "            rects = detector.detectMultiScale(\n",
    "                cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), scaleFactor=1.1, \n",
    "                minNeighbors=5, minSize=(30, 30))\n",
    "            # loop over the face detections and draw them on the frame\n",
    "            for (x, y, w, h) in rects:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            total += 1\n",
    "            p = os.path.sep.join([output, \"{}.png\".format(\n",
    "                str(total).zfill(5))])\n",
    "            cv2.imwrite(p, orig)\n",
    "    print(\"[INFO] {} face images stored in {}\".format(total, name))\n",
    "    print(\"[INFO] cleaning up...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_data_from_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_face_data():\n",
    "    # grab the paths to the input images in our dataset\n",
    "    print(\"[INFO] quantifying faces...\")\n",
    "    \n",
    "    # Face recognition dataset\n",
    "    dataset = 'face_recognition_dataset/'\n",
    "    \n",
    "    # Output encoding file\n",
    "    encodings_file = 'encodings.pickle'\n",
    "    \n",
    "    # Face detection method (cnn or hog)\n",
    "    detection_method = 'cnn'\n",
    "    imagePaths = list(paths.list_images(dataset))\n",
    "    \n",
    "    # initialize the list of known encodings and known names\n",
    "    knownEncodings = []\n",
    "    knownNames = []\n",
    "    \n",
    "    # loop over the image paths\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        \n",
    "        # extract the person name from the image path\n",
    "        print(\"[INFO] processing image {}/{}\".format(i + 1,\n",
    "            len(imagePaths)))\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "        \n",
    "        # load the input image and convert it from BGR (OpenCV ordering)\n",
    "        # to dlib ordering (RGB)\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # detect the (x, y)-coordinates of the bounding boxes\n",
    "        # corresponding to each face in the input image\n",
    "        # face_recognition.face_locations\n",
    "        \"\"\"img – An image (as a numpy array)\n",
    "        number_of_times_to_upsample – How many times to upsample the \n",
    "        image looking for faces. Higher numbers find smaller faces.\n",
    "        model – Which face detection model to use. “hog” is less \n",
    "        accurate but faster on CPUs. “cnn” is a more accurate \n",
    "        deep-learning model which is GPU/CUDA accelerated (if \n",
    "        available). The default is “hog”.\n",
    "        Returns: A list of tuples of found face locations in css (top,\n",
    "        right, bottom, left) order\"\"\"\n",
    "        boxes = face_recognition.face_locations(rgb,\n",
    "            model=detection_method)\n",
    "        \n",
    "        \n",
    "        # compute the facial embedding for the face\n",
    "        # face_encodings()\n",
    "        \"\"\"face_image – The image that contains one or more faces\n",
    "        known_face_locations – Optional - the bounding boxes of each\n",
    "        face if you already know them.\n",
    "        Returns: A list of 128-dimensional face encodings (one for\n",
    "        each face in the image)\"\"\"\n",
    "        encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        \n",
    "        # loop over the encodings\n",
    "        for encoding in encodings:\n",
    "            # add each encoding + name to our set of known names and\n",
    "            # encodings\n",
    "            knownEncodings.append(encoding)\n",
    "            knownNames.append(name)\n",
    "\n",
    "\n",
    "    # dump the facial encodings + names to disk\n",
    "    print(\"[INFO] serializing encodings... to \",encodings_file)\n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    f = open(encodings_file, \"wb\")\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()        \n",
    "    print(\"Total Images Encoded:\", len(knownNames))\n",
    "    print(\"Total Faces Encoded:\", len(set(knownNames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces_from_image():\n",
    "    try:\n",
    "        while True:\n",
    "            while True:\n",
    "                img_name = input('Enter image file name(with extension), image must be in recognize_faces folder: ')\n",
    "                img_path = 'recognize_faces/' + img_name\n",
    "                if path.exists(img_path):\n",
    "                    break\n",
    "                else:\n",
    "                    print('File Not Found!')\n",
    "            \n",
    "            encodings_file = 'encodings.pickle'                \n",
    "            detection_method = 'hog'\n",
    "            \n",
    "            # load the known faces and embeddings\n",
    "            print(\"[INFO] loading encodings...\")\n",
    "            data = pickle.loads(open(encodings_file, \"rb\").read())\n",
    "            # load the input image and convert it from BGR to RGB\n",
    "\n",
    "\n",
    "\n",
    "            image = cv2.imread(img_path)\n",
    "            image = cv2.resize(image, (600,600))\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # detect the (x, y)-coordinates of the bounding boxes corresponding\n",
    "            # to each face in the input image, then compute the facial embeddings\n",
    "            # for each face\n",
    "            print(\"[INFO] recognizing faces...\")\n",
    "            boxes = face_recognition.face_locations(rgb,\n",
    "                model=detection_method)\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "            # initialize the list of names for each face detected\n",
    "            names = []\n",
    "\n",
    "            # loop over the facial embeddings\n",
    "            for encoding in encodings:\n",
    "                # attempt to match each face in the input image to our known\n",
    "                # encodings\n",
    "                matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "                    encoding)\n",
    "                name = \"Unknown\"\n",
    "\n",
    "                # check to see if we have found a match\n",
    "                if True in matches:\n",
    "                    # find the indexes of all matched faces then initialize a\n",
    "                    # dictionary to count the total number of times each face\n",
    "                    # was matched\n",
    "                    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                    counts = {}\n",
    "                    # loop over the matched indexes and maintain a count for\n",
    "                    # each recognized face face\n",
    "                    for i in matchedIdxs:\n",
    "                        name = data[\"names\"][i]\n",
    "                        counts[name] = counts.get(name, 0) + 1\n",
    "                    # determine the recognized face with the largest number of\n",
    "                    # votes (note: in the event of an unlikely tie Python will\n",
    "                    # select first entry in the dictionary)\n",
    "                    name = max(counts, key=counts.get)\n",
    "\n",
    "                # update the list of names\n",
    "                names.append(name)\n",
    "\n",
    "\n",
    "            # loop over the recognized faces\n",
    "            for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "                # draw the predicted face name on the image\n",
    "                cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                y = top - 15 if top - 15 > 15 else top + 15\n",
    "                cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.75, (0, 255, 0), 2)\n",
    "            # show the output image\n",
    "            cv2.imshow(\"To test another photo press c, else q to quit\", image)\n",
    "            l = cv2.waitKey(0) & 0xFF\n",
    "            if l==ord('q'):\n",
    "                break\n",
    "    except:\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Memory Error, Call to cuDNN failed\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize_faces_from_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face_live_stream():\n",
    "    # Initializing variables\n",
    "    encodings = \"encodings.pickle\"\n",
    "    display = 1\n",
    "    detection_method = 'hog'\n",
    "    \n",
    "    # load the known faces and embeddings\n",
    "    print(\"[INFO] loading encodings...\")\n",
    "    data = pickle.loads(open(encodings, \"rb\").read())\n",
    "    \n",
    "    # initialize the video stream and pointer to output video file, then\n",
    "    # allow the camera sensor to warm up\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # loop over frames from the video file stream\n",
    "    try:\n",
    "        while True:\n",
    "            # grab the frame from the threaded video stream\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # convert the input frame from BGR to RGB then resize it to have\n",
    "            # a width of 750px (to speedup processing)\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # resize with aspect ratio\n",
    "            rgb = imutils.resize(frame, width=750)\n",
    "            r = frame.shape[1] / float(rgb.shape[1])\n",
    "            \n",
    "            # detect the (x, y)-coordinates of the bounding boxes\n",
    "            # corresponding to each face in the input frame, then compute\n",
    "            # the facial embeddings for each face\n",
    "            boxes = face_recognition.face_locations(rgb,\n",
    "                model=detection_method)\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "            names = []\n",
    "\n",
    "            # loop over the facial embeddings\n",
    "            for encoding in encodings:\n",
    "                \n",
    "                # attempt to match each face in the input image to our known encodings\n",
    "                matches = face_recognition.compare_faces(data[\"encodings\"],\n",
    "                    encoding)\n",
    "                name = \"Unknown\"\n",
    "                \n",
    "                # check to see if we have found a match\n",
    "                if True in matches:\n",
    "                \n",
    "                    # find the indexes of all matched faces then initialize a\n",
    "                    # dictionary to count the total number of times each face\n",
    "                    # was matched\n",
    "                    matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                    counts = {}\n",
    "                    \n",
    "                    # loop over the matched indexes and maintain a count for\n",
    "                    # each recognized face face\n",
    "                    for i in matchedIdxs:\n",
    "                        name = data[\"names\"][i]\n",
    "                        counts[name] = counts.get(name, 0) + 1\n",
    "                    \n",
    "                    # determine the recognized face with the largest number\n",
    "                    # of votes (note: in the event of an unlikely tie Python\n",
    "                    # will select first entry in the dictionary)\n",
    "                    name = max(counts, key=counts.get)\n",
    "\n",
    "                # update the list of names\n",
    "                names.append(name)\n",
    "\n",
    "\n",
    "            # loop over the recognized faces\n",
    "            for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "                \n",
    "                # rescale the face coordinates\n",
    "                top = int(top * r)\n",
    "                right = int(right * r)\n",
    "                bottom = int(bottom * r)\n",
    "                left = int(left * r)\n",
    "                \n",
    "                # draw the predicted face name on the image\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom),\n",
    "                    (0, 255, 0), 1)\n",
    "                y = top - 15 if top - 15 > 15 else top + 15\n",
    "                cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.75, (0, 255, 0), 2)\n",
    "\n",
    "            cv2.imshow(\"Press q to quit\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                break    \n",
    "\n",
    "        # do a bit of cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "\n",
    "    except:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        print(\"Memory Error, Call to cuDNN failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recognize_face_live_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****MENU****\n",
      "Press 1 to add new face though images\n",
      "               Press 2 to add new face via live stream\n",
      "               Press 3 to recognize faces in images\n",
      "               Press 4 to recognize faces in live video stream \n",
      "               Press 5 to quit: \n",
      "4\n",
      "[INFO] loading encodings...\n",
      "[INFO] starting video stream...\n",
      "Memory Error, Call to cuDNN failed\n",
      "\n",
      "\n",
      "****MENU****\n",
      "Press 1 to add new face though images\n",
      "               Press 2 to add new face via live stream\n",
      "               Press 3 to recognize faces in images\n",
      "               Press 4 to recognize faces in live video stream \n",
      "               Press 5 to quit: \n",
      "5\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"\\n\\n****MENU****\")\n",
    "    t = int(input('Press 1 to add new face though images\\n \\\n",
    "              Press 2 to add new face via live stream\\n \\\n",
    "              Press 3 to recognize faces in images\\n \\\n",
    "              Press 4 to recognize faces in live video stream \\n \\\n",
    "              Press 5 to quit: \\n'))\n",
    "    if t==1:\n",
    "        add_face_data_from_images()\n",
    "        print('Please wait, updating the encoding files')\n",
    "        encode_face_data()\n",
    "    elif t==2:\n",
    "        add_face_data_from_video()\n",
    "        print('Please wait, updating the encoding files')\n",
    "        encode_face_data()\n",
    "    elif t==3:\n",
    "        recognize_faces_from_image()\n",
    "    elif t==4:\n",
    "        recognize_face_live_stream()\n",
    "    elif t==5:\n",
    "        break\n",
    "    else:\n",
    "        print('Invalid Entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
